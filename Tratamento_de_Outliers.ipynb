{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tratamento de Outliers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHrHhirif8HSV0W4TQekgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silveiraluiza/machine-learning/blob/main/Tratamento_de_Outliers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-U1w2gEbpXi"
      },
      "source": [
        "## Importando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yfd50cmbUIB"
      },
      "source": [
        "# load and summarize the dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(url, header=None)\n",
        "\n",
        "def create_X_y_df(df):\n",
        "  # retrieve the array\n",
        "  data = df.values\n",
        "  # split into input and output elements\n",
        "  X, y = data[:, :-1], data[:, -1]\n",
        "  # split into train and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "  # summarize the shape of the train and test sets\n",
        "  return X_train, X_test, y_train, y_test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CnnNxn3bmHN"
      },
      "source": [
        "## Modelo Baseline\n",
        "\n",
        "O modelo baseline utilizado pelo artigo é uma regressão, onde é previsto um valor numérico para o preço de uma casa. Todas as variáveis de entrada são também numéricas.\n",
        "\n",
        "A avaliação das previsões é feita utilizando o erro médio absoluto (MAE) no artigo base, portanto iremos seguir utilizando a mesma para comparações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SYGuly4blTd",
        "outputId": "cb6378fb-7cb0-4ecb-dbb6-58231b8b25d6"
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = create_X_y_df(df)\n",
        "\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 3.417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V28iRQiGfb0O"
      },
      "source": [
        "## MAEs dos métodos utilizados no artigo\n",
        "\n",
        "### Isolation Forest\n",
        "> MAE: 3.189\n",
        "\n",
        "### Minimum Covariance Determinant\n",
        "> MAE: 3.388\n",
        "\n",
        "### Local Outlier Factor\n",
        "> MAE: 3.356\n",
        "\n",
        "### One-Class SVM\n",
        "> MAE: 3.431\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAuLc7j1cdnV"
      },
      "source": [
        "## Z-Score\n",
        "\n",
        "\n",
        "Em termos simples, o Z-score é uma medida estatística que diz a que distância está um ponto de dados do resto do conjunto de dados. Em um termo mais técnico, o Z-score indica a quantos desvios padrão uma determinada observação está longe da média.\n",
        "\n",
        "O  Z-score é uma medida paramétrica e requer dois parâmetros - média e desvio padrão. Se o score Z de um ponto de dados for superior a 3, indica que o ponto de dados é bastante diferente dos outros pontos. Ele então pode ser tido como um outlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkf8E_tFcdJ9",
        "outputId": "97b3efbb-a461-4e22-da30-ba5e13eb0ef1"
      },
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_test, y_train, y_test = create_X_y_df(df)\n",
        "\n",
        "print(\"Tamanho do X_train antes de remover os outliers: {}\".format(X_train.shape))\n",
        "z_scores = stats.zscore(X_train)\n",
        "abs_z_scores = np.abs(z_scores)\n",
        "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
        "\n",
        "X_train = X_train[filtered_entries]\n",
        "y_train = y_train[filtered_entries]\n",
        "\n",
        "print(\"Tamanho do X_train após remover os outliers: {}\".format(X_train.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho do X_train antes de remover os outliers: (339, 13)\n",
            "Tamanho do X_train após remover os outliers: (276, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDyRWmT49U3a"
      },
      "source": [
        "### Treinando o modelo baseline com o dataset sem outliers (Z-Score)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RhO8LDndCcF",
        "outputId": "a1f42739-7a6a-4e9f-e86f-e9a5e08ef69d"
      },
      "source": [
        "\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 3.263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1lPU_QBBV34"
      },
      "source": [
        "Usando a abordagem do Z-Score, obtivemos uma MAE de 3.270, que é menor do que a do modelo baseline e menor também do que a maioria das MAEs encontradas, menos a do método de isolation forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6u-GJ80ewHf"
      },
      "source": [
        "## DBScan\n",
        "\n",
        "DBSCAN é uma abordagem de agrupamento com base na densidade, e não um método de identificação de anomalias por si só. Ele desenvolve agrupamentos com base numa medida de distância. Os pontos centrais - pontos que têm um mínimo de pontos no seu redor - e pontos que estão suficientemente próximos desses pontos centrais juntos formam um grupo.\n",
        "\n",
        "Podemos usar DBSCAN como um algoritmo de detecção de outlier porque os pontos que não pertencem a nenhum aglomerado adquirem a sua própria classe: -1. O algoritmo tem dois parâmetros (epsilon: escala de comprimento, e min_sample: o número mínimo de amostras necessárias para que um ponto seja um ponto central). Encontrar um bom epsilon é crítico.\n",
        "\n",
        "DBSCAN faz portanto previsões binárias: um ponto ou é um outlier ou não. Para refinar as previsões, consideramos os outros aglomerados para além do aglomerado principal, também como aglomerados outliers, quanto menor for o aglomerado, maior será a pontuação outliers.\n",
        "\n",
        "A função de distância utilizada é a distância euclidiana padrão. Note-se que o pior desempenho do DBSCAN é O(n^2), se a varredura de vizinhança for uma varredura linear, o que é o caso da implementação do sci-kit learn implementation. Isto limita significativamente o tamanho do conjunto de dados que pode ser analisado.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLF9k5vaeyN5",
        "outputId": "1716966f-643a-40fe-a148-9e36ad1cbbf0"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from numpy import random, where\n",
        "\n",
        "mae_list = []\n",
        "eps_samples = []\n",
        "\n",
        "# Variamos o epsilon e o min_sample para obter melhores resultados\n",
        "\n",
        "for eps in (0.3, 0.5, 1, 5, 10, 20, 30, 40, 50):\n",
        "  for min_samples in (3, 5, 10, 15, 20, 30):\n",
        "    dbscan = DBSCAN(eps = eps, min_samples = min_samples)\n",
        "    X_train, X_test, y_train, y_test = create_X_y_df(df)\n",
        "    pred = dbscan.fit_predict(X_train)\n",
        "    index_non_anom = where(pred != -1)\n",
        "\n",
        "    if index_non_anom[0].shape[0] > 200:\n",
        "      mask = index_non_anom[0]\n",
        "      \n",
        "      X_train, y_train = X_train[mask, :], y_train[mask]\n",
        "      # fit the model\n",
        "      model = LinearRegression()\n",
        "      model.fit(X_train, y_train)\n",
        "      # evaluate the model\n",
        "      y_pred = model.predict(X_test)\n",
        "      # evaluate predictions\n",
        "      mae = mean_absolute_error(y_test, y_pred)\n",
        "      eps_samples.append((eps,min_samples))\n",
        "      mae_list.append(mae)\n",
        "      print(\"--------------------------\")\n",
        "      print(mae)\n",
        "      print((eps,min_samples))\n",
        "      print(filtered_entries.shape)\n",
        "\n",
        "print(\"--------------------------\")\n",
        "print(\"Menor MAE\")\n",
        "print(min(mae_list))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------\n",
            "3.420371501345386\n",
            "(20, 3)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.5382556600347517\n",
            "(20, 5)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.2664418344507906\n",
            "(30, 3)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.3096989638552423\n",
            "(30, 5)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.663021654401295\n",
            "(30, 10)\n",
            "(339,)\n",
            "--------------------------\n",
            "8.155231037588123\n",
            "(30, 15)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.429035959630473\n",
            "(40, 3)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.401218051788704\n",
            "(40, 5)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.3023915761425924\n",
            "(40, 10)\n",
            "(339,)\n",
            "--------------------------\n",
            "4.556643048942376\n",
            "(40, 15)\n",
            "(339,)\n",
            "--------------------------\n",
            "5.283978798472505\n",
            "(40, 20)\n",
            "(339,)\n",
            "--------------------------\n",
            "5.723088356783139\n",
            "(40, 30)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.4202931253955033\n",
            "(50, 3)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.4201103145642904\n",
            "(50, 5)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.380718799459045\n",
            "(50, 10)\n",
            "(339,)\n",
            "--------------------------\n",
            "3.3003416735538056\n",
            "(50, 15)\n",
            "(339,)\n",
            "--------------------------\n",
            "4.55534824916617\n",
            "(50, 20)\n",
            "(339,)\n",
            "--------------------------\n",
            "4.6074813106502726\n",
            "(50, 30)\n",
            "(339,)\n",
            "--------------------------\n",
            "Menor MAE\n",
            "3.2664418344507906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ots0YLgEsyvg",
        "outputId": "0ea9f61f-6fce-46de-8f07-f177182f697a"
      },
      "source": [
        "index = mae_list.index(3.2664418344507906)\n",
        "eps_samples[index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4hL8ZSwC140"
      },
      "source": [
        "### Treinando o modelo baseline com o dataset sem outliers (DBSCAN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyvfVOX70Jfw",
        "outputId": "11182c30-ee74-4ba9-8ed5-62428fdcfccd"
      },
      "source": [
        "dbscan = DBSCAN(eps = 30, min_samples = 3)\n",
        "X_train, X_test, y_train, y_test = create_X_y_df(df)\n",
        "print(\"Tamanho do X_train antes de remover os outliers: {}\".format(X_train.shape))\n",
        "\n",
        "pred = dbscan.fit_predict(X_train)\n",
        "index_non_anom = where(pred != -1)\n",
        "mask = index_non_anom[0]\n",
        "\n",
        "X_train, y_train = X_train[mask, :], y_train[mask]\n",
        "print(\"Tamanho do X_train após remover os outliers: {}\".format(X_train.shape))\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho do X_train antes de remover os outliers: (339, 13)\n",
            "Tamanho do X_train após remover os outliers: (307, 13)\n",
            "MAE: 3.266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyQbFVMSC8Bm"
      },
      "source": [
        "Usando a abordagem do DBSCAN, obtivemos uma MAE de 3.266, que é menor do que a do modelo baseline e, assim como o Z-score, menor também do que a maioria das MAEs encontradas, menos a do método de isolation forest. Ela é bastante similar a MAE do Z-Score, sendo maior apenas por 0.003 pontos, no entanto remove menos dados e obtém um resultado bastante semelhante."
      ]
    }
  ]
}